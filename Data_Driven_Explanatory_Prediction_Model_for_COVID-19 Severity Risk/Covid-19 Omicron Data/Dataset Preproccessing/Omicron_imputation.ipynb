{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omicron Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from xlsxwriter import Workbook\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = '/Data.xlsx' \n",
    "dataset = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the datetime values with NaN in the WBC column\n",
    "dataset['WBC'] = pd.to_numeric(dataset['WBC'], errors='coerce')\n",
    "\n",
    "# Check for other non-numeric types again to ensure all are handled\n",
    "object_columns = dataset.select_dtypes(include=['object']).columns\n",
    "unique_values = {col: dataset[col].unique() for col in object_columns}\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing value Imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GENDER                   24.770642\n",
       "D-DIMERS_cleaned         16.972477\n",
       "TnI                      16.055046\n",
       "FIBRINOGEN               15.596330\n",
       "DIRECT BIL               12.385321\n",
       "BIL                      10.550459\n",
       "FERRITIN                 10.091743\n",
       "TEMP                     10.091743\n",
       "INR                       8.256881\n",
       "APTT                      8.256881\n",
       "HCO3                      7.798165\n",
       "URTIx                     7.798165\n",
       "DYSPNEAx                  6.422018\n",
       "Systolic_BP               5.963303\n",
       "PCO2                      5.963303\n",
       "DIARRHEASx                5.963303\n",
       "PULSE RATE                5.963303\n",
       "Diastolic_BP              5.963303\n",
       "Outcome_numerical         4.128440\n",
       "PH                        3.669725\n",
       "PO2/FIO2                  3.669725\n",
       "FATIGUEx                  3.669725\n",
       "COUGHx                    3.211009\n",
       "CCI                       3.211009\n",
       "LDH                       3.211009\n",
       "FIO2 eisagwgh_cleaned     2.752294\n",
       "SGOT                      2.293578\n",
       "FEVERx                    2.293578\n",
       "PO2                       2.293578\n",
       "K                         2.293578\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the percentage of missing values per column\n",
    "missing_values_percentage = dataset.isnull().mean() * 100\n",
    "\n",
    "# Display the results\n",
    "missing_values_percentage_sorted = missing_values_percentage.sort_values(ascending=False)\n",
    "missing_values_percentage_sorted.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (3004763486.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    discrete_columns = ['GENDER', 'INTUBATION', 'CPAP', 'HIGH FLOW', 'WHO score', \"qSOFA\", \"Outcome_numerical\", \"FEVERx\",\t\"COUGHx\",\t'FATIGUEx\",\t\"DIARRHEASx\",\t\"DYSPNEAx\",\t\"URTIx\"]\u001b[0m\n\u001b[0m                                                                                                                         \t         \t           \t             \t           \t        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# Identify continuous and discrete columns\n",
    "discrete_columns = ['GENDER', 'INTUBATION', 'CPAP', 'HIGH FLOW', 'WHO score', \"qSOFA\", \"Outcome_numerical\", \"FEVERx\",\t\"COUGHx\",\t\"FATIGUEx\",\t\"DIARRHEASx\",\t\"DYSPNEAx\",\t\"URTIx\"]\n",
    "continuous_columns = [col for col in dataset.columns if col not in discrete_columns]\n",
    "\n",
    "# Impute continuous columns\n",
    "continuous_data = dataset[continuous_columns]\n",
    "\n",
    "# Initialize the IterativeImputer with RandomForestRegressor\n",
    "imputer = IterativeImputer(estimator=RandomForestRegressor(n_estimators=5, max_depth=None, random_state=42),\n",
    "                            max_iter=10, random_state=42)\n",
    "\n",
    "# Perform the imputation for continuous data\n",
    "data_imputed = imputer.fit_transform(continuous_data)\n",
    "\n",
    "# Convert the imputed data back to a DataFrame\n",
    "data_imputed_df = pd.DataFrame(data_imputed, columns=continuous_columns)\n",
    "data_imputed_df.index = dataset.index\n",
    "\n",
    "# Replace the original continuous columns in the dataset with the imputed data\n",
    "for column in continuous_columns:\n",
    "    dataset[column] = data_imputed_df[column]\n",
    "\n",
    "# Define the function for imputing discrete columns using RandomForestClassifier\n",
    "def impute_numerical_discrete_rf(data, column, other_columns):\n",
    "    # Prepare the training data (where column is not missing)\n",
    "    train = data[data[column].notnull()]\n",
    "    test = data[data[column].isnull()]\n",
    "\n",
    "    if not test.empty:\n",
    "        X_train = train[other_columns]\n",
    "        y_train = train[column].astype('int')  # Ensure the target is integer\n",
    "        X_test = test[other_columns]\n",
    "\n",
    "        # Initialize and train classifier\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict and fill missing values\n",
    "        predicted_values = clf.predict(X_test)\n",
    "        data.loc[data[column].isnull(), column] = predicted_values\n",
    "\n",
    "    return data\n",
    "\n",
    "# List of other columns to use as predictors; typically all other columns except the one being imputed\n",
    "other_columns = [col for col in dataset.columns if col not in discrete_columns]\n",
    "\n",
    "# Apply the imputation for each discrete column\n",
    "for col in discrete_columns:\n",
    "    dataset = impute_numerical_discrete_rf(dataset, col, other_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values per column\n",
    "missing_values_percentage = dataset.isnull().mean() * 100\n",
    "\n",
    "# Display the results\n",
    "missing_values_percentage_sorted = missing_values_percentage.sort_values(ascending=False)\n",
    "missing_values_percentage_sorted.head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
